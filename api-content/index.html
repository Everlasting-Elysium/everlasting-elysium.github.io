{"posts":[{"title":"Chrome等浏览器图片加载不出来","content":"今天调试前端时，发现部分图片展示不出来，但图片链接没有问题，后发现控制台报错：net::ERR_BLOCKED_BY_CLIENT 如下图所示： 排查发现，是浏览器安装的某个第三方扩展程序已阻止对此网页的访问，例如：uBlock Origin。 换未装插件的浏览器测试，发现可以加载。 解决方案： 将工程页面加入第三方扩展白名单。 ","link":"https://everlasting-elysium.github.io/chrome-deng-liu-lan-qi-xia-chu-xian-neterr_blocked_by_client/"},{"title":"功能未动，测试先行","content":"最近在看了《测试驱动开发》一书，对其中的观点深以为然。 会想起之前在好说工作的日子，由于人员紧缺，但又急需新功能上线，从而刺激用户的增长和提高用户的粘性。那段时间的开发可以称之为昏天黑地，经常一周就是一两个大功能上线，也不会专门去写一些测试，功能跑通就上线，也由此埋下了祸端。 2023年底，由于前期设计不足和需求，导致服务无法支撑较大用户量的同时聊天。架构优化由此开始，但多走一步就是地狱。 没有测试，没有历史需求文档，在这种情况下拆解服务，没走一步都是万丈深渊。过程也可谓曲折： 找历史需求单子 找产品 啃五花八门的代码 找相关的开发同学 测试提交大量bug单 。。。 好在最后，磕磕绊绊的完成了微服务的拆分。后来，就开始留意代码的测试。时间一长，发现其却又存在的意义：一方面完善的测试可以更好的辅助开发，降低开发的心智成本，不用随时担心会不会因为修改什么导致已有功能的损坏。二来，轻装前行，不必每次都需要手动测试相关功能。 目前个人形成的工作流如下： 在开发时间合理的情况下： 完成功能测试，一来可以帮自己梳理业务逻辑，二来可以更好的和产品沟通业务逻辑。 开发代码 完成单元测试。 根据业务持续迭代相关测试。 如果时间紧张： 优先完成功能，并将需要测试的部分又TODO标记 功能完成后，根据时间和测试同时进行测试，并将测试反馈的问题补充到测试中 定期检测代码中的TODO项，进行完善。 善用AI工具 根据经验制作地代码工具帮助自己写测试。 后续有优化回来补充。 这套工作流在我目前的工作中，确实提供了不少便利，也希望这篇文章能对此时的你有所帮助。 ","link":"https://everlasting-elysium.github.io/gong-neng-wei-dong-ce-shi-xian-xing/"},{"title":"服务性能优化：从 Redis 到 Memcache 的降本增效之路","content":"近期，所负责的服务在性能方面遭遇严峻挑战，难以支撑当前业务的 QPS。 为解决这一问题，我们对业务进行了深入分析，情况如下： 核心任务数据的查询占据整体查询的 50%，涵盖任务流程、能力调用方式等基础信息。 业务具体任务查询量同样占比 50%，其中近 10 天的数据占比高达 95%。 业务具体任务的写入占比达 99.9%，剩余部分为业务的调整更新。 设计了最初的方案，大致如下： 将核心的任务数据做长时间缓存，并打散更新时间，防止缓存雪崩。 将近10天的任务数据做短时间缓存，降低业务查询的压力，将数据库资源尽可能的让给数据库写入。 由于是集群部署，所以使用redis作为缓存。 方案是自信满满的提交的，被问的时候人是傻的：redis是要钱的，有没有其他方案。。。这是我想起了，项目组季度目标中一条：降本增效🤡。 所以，怎么在不使用redis的前提下提高服务性能？ 最后经过项目参与人员的讨论，决定使用memcache进行优化。具体方案如下： 对核心任务数据用memcache进行缓存，并做每秒刷新。降低查询压力的同时，保证任务有较高的时效性，同时留出强制刷新接口用于必要时对每个实例强制刷新。 对于数据库的插入，改为批量操作。该优化是基于目前的任务完成所需时间远小于要求的时间，通过批量操作提高数据写入能力。 对任务数据进行天级分表，减缓之前因为数据备份导致时导致的主从同步延迟。同时提高表的查询效率。 经过以上优化，数据的读压力降低了45%，性能也达到了预期目标。 总结：之前在处理优化时，基本上没有考虑过成本问题，因为没有收到过来自这方面的压力，更多的时老板对于性能的不满意，而这次却体会到了什么叫综合考虑，也算是有所进步吧～ ","link":"https://everlasting-elysium.github.io/fu-wu-xing-neng-you-hua-cong-redis-dao-memcache-de-jiang-ben-zeng-xiao-zhi-lu/"},{"title":"关于一次优化","content":"还是炸了，果然一个东西，如果要改到基本看不出原来的样子，最好的方案还是重做，轻装前行。 如果要过要改一个东西，这个东西改完基本看不出原来的样子，如果是你，你怎么选择： 改！ 重做 好吧，我们讨论下来是选择1，因为没时间。既然大家选择了这么走，先试试吧。 💩山是怎么练成的 任务分好了，用户模块。让我看看当时别人怎么写的，看了一天。。。。。，艹，总结出如下问题： 用户表字段太多，平时能用到的，用不到的，全在里面。 索引没改，好多查询都覆盖不到了。 一个SELECT 一个缓存，这么大字段，倒是拆一下啊。。。 好了好了，找到问题就可以下手了，好在单测还是有的，能省点儿事儿。目前看下来， 大部分业务只用在用户这块只用ID，UID，name，descrpition，status这几个字段，为了减少更新所需要的时间，先把他们拆下来，缓存也可以跟着拆一下。 目前30w这个量，加上缓存压力不大，先不考虑分库。 优化SQL 重建索引 另外的发现 SELECT id,name FROM users OFFSET 200000 LIMIT 10,请问这个SQL有问题么？我当时觉得没问题，后来是有的： 这样会导致扫描的行数过多，SQL会很慢。 怎么解决： 目前是自己缓存当前page的最后一个用户ID,用于下一个page的查询，SQL改为: SELECT id,name FROM users WHERE id &gt; N OFFSET 200000 LIMIT 10 🔚 好了好了，搞完了，常回来看看，上述问题，以后注意，自己别犯。 ","link":"https://everlasting-elysium.github.io/guan-yu-yi-ci-you-hua/"}]}